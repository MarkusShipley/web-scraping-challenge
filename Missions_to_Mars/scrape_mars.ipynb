{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "# Import Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import html5lib\n",
    "import lxml\n",
    "from splinter import Browser\n",
    "import pymongo\n",
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pymongo\n",
    "from flask import Flask, render_template\n",
    "\n",
    "\n",
    "        # In[18]:\n",
    "\n",
    "\n",
    "        # Set the executable path and initialize Splinter\n",
    "\n",
    "executable_path = {\"executable_path\": \"./chromedriver.exe\"}\n",
    "browser = Browser(\"chrome\", **executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    \n",
    "    # In[13]:\n",
    "\n",
    "    mars_info_dictionary = dict()\n",
    "    # NASA Mars News \n",
    "    # Scrape the [Mars News Site](https://redplanetscience.com/) and collect the latest News Title and Paragraph Text. \n",
    "    # Assign the text to variables that you can reference later.\n",
    "\n",
    "    # Visit the Maars News Site provided in the insructions\n",
    "\n",
    "    url = 'https://redplanetscience.com/'\n",
    "    browser.visit(url)\n",
    "\n",
    "\n",
    "    # In[15]:\n",
    "\n",
    "\n",
    "    # News Title\n",
    "\n",
    "    # Using Beautiful Soup, the broswer html will be converted to a soup object.Convert the browser html to a soup object.\n",
    "    # To collect the latest News Title and Paragraph Text. I am going to the site and inspect the onject to get the classes for\n",
    "    # the title and paragraph. According to inspect process <div class=\"content_title> is the class\n",
    "    # Note: Can use soup because that is the name assigned when importing in bs.\n",
    "\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    news_title = soup.find('div', class_='content_title')\n",
    "    #news_title.text\n",
    "\n",
    "\n",
    "    # In[16]:\n",
    "\n",
    "\n",
    "    # After locating the headline, referenced the news_title variable and the .text.strip() functions to make the news title\n",
    "    # regular text without the html markup\n",
    "    #https://python.hotexamples.com/examples/bs4/BeautifulSoup/strip/python-beautifulsoup-strip-method-examples.html\n",
    "\n",
    "    news_title = news_title.text.strip()\n",
    "    #print(news_title)\n",
    "    mars_info_dictionary['news_titles'] = news_title\n",
    "\n",
    "    # In[17]:\n",
    "\n",
    "\n",
    "    #News Paragraph \n",
    "\n",
    "    # According to the inspect process <div class=\"article_teaser_body\">\n",
    "\n",
    "    news_paragraph = soup.find('div', class_='article_teaser_body')\n",
    "    news_paragraph\n",
    "\n",
    "    # In[18]:\n",
    "\n",
    "\n",
    "    # After locating the paragraph, referenced the news_paragraph variable and the .text.strip() functions to make the \n",
    "    # paragraph regular text without the html markup\n",
    "    #https://python.hotexamples.com/examples/bs4/BeautifulSoup/strip/python-beautifulsoup-strip-method-examples.html\n",
    "\n",
    "    news_paragraph = news_paragraph.text.strip()\n",
    "    #print(news_paragraph)\n",
    "    mars_info_dictionary['news_paragraph'] = news_paragraph\n",
    "\n",
    "    # In[8]:\n",
    "\n",
    "\n",
    "    # JPL Mars Space Images - Featured Image\n",
    "\n",
    "\n",
    "    # In[27]:\n",
    "\n",
    "\n",
    "    # Visit the url for the Featured Space Image site [here](https://spaceimages-mars.com).\n",
    "    # Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the \n",
    "    # url string to a variable called `featured_image_url`.\n",
    "    # Make sure to find the image url to the full size `.jpg` image.\n",
    "    # Make sure to save a complete url string for this image.\n",
    "\n",
    "    url_2 = \"https://spaceimages-mars.com/\"\n",
    "    browser.visit(url_2)\n",
    "\n",
    "\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    img = soup.find('img', class_='headerimage fade-in')\n",
    "    img_link = img['src']\n",
    "\n",
    "    featured_image_url = url_2 + img_link\n",
    "\n",
    "    mars_info_dictionary ['featured_image'] = featured_image_url \n",
    "\n",
    "    # In[11]:\n",
    "\n",
    "\n",
    "    ###Scrape the table containing facts about diameter of Mars\n",
    "    #!pip install html5lib\n",
    "\n",
    "    url_3 = \"https://galaxyfacts-mars.com/\"\n",
    "\n",
    "\n",
    "    # In[13]:\n",
    "\n",
    "    df = pd.read_html(url_3)\n",
    "    #display(df[1])\n",
    "    mars_df = (df[1])\n",
    "    \n",
    "    mars_df.columns = ['name', 'measure']\n",
    "    #mars_df\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    # Converting df to html in case it is needed for the flask portion of the exercise\n",
    "    #mars_df.to_html(buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None,index_names=True, justify=None, bold_rows=True, classes=None, escape=True, max_rows=None, max_cols=None, show_dimensions=False, notebook=False)\n",
    "\n",
    "    mars_info_dictionary['mars_facts'] = mars_df.to_dict('records')\n",
    "\n",
    "    # In[50]:\n",
    "\n",
    "\n",
    "    #Create empty dictionary for results\n",
    "    hemisphere_image_urls = {}\n",
    "\n",
    "    #Define the url\n",
    "    url_4 = \"https://marshemispheres.com/\"\n",
    "\n",
    "    #Go to main website\n",
    "    browser.visit(url_4)\n",
    "\n",
    "    #Read page as HTML\n",
    "    html = browser.html\n",
    "\n",
    "    #Parse HTML\n",
    "    soup = bs(html, 'html.parser')\n",
    "\n",
    "    #Find area that represents the list with hemispheres\n",
    "    nav_list = soup.find('div', class_=\"collapsible results\")\n",
    "\n",
    "    #From the above area find every item in the list\n",
    "    all_hemispheres = nav_list.find_all('div', class_=\"item\")\n",
    "\n",
    "    #Extract image link for each hemisphere\n",
    "    for hemisphere in all_hemispheres:\n",
    "        #Find hemisphere name\n",
    "        hemisphere_name = hemisphere.find('h3').text\n",
    "\n",
    "        #Find the link to hemiphere page\n",
    "        link = hemisphere.find('a', class_ = \"itemLink product-item\")['href']\n",
    "\n",
    "        #Create a full URL for hemishphere page\n",
    "        hemisphere_link = url_4 + link\n",
    "\n",
    "        #Go to hemisphere page\n",
    "        browser.visit(hemisphere_link)\n",
    "\n",
    "        #Read page as HTML\n",
    "        html = browser.html\n",
    "\n",
    "        #Parse HTML\n",
    "        soup = bs(html, 'html.parser')\n",
    "\n",
    "        #Extract link to full image\n",
    "        img = soup.find('img', class_='wide-image')\n",
    "        hemisphere_img_link = img['src']\n",
    "\n",
    "        #Create a full URL for hemisphere image\n",
    "        hemisphere_image_url = url_4 + hemisphere_img_link\n",
    "\n",
    "        #Add hemisphere name and hemisphere url to dictionary with results\n",
    "        hemisphere_image_urls[hemisphere_name] = hemisphere_image_url\n",
    "\n",
    "    browser.quit()    \n",
    "    \n",
    "    #Create one dictionary with all the data\n",
    "    mars_info_dictionary['hemisphere_images'] = hemisphere_image_urls\n",
    "\n",
    "    return mars_info_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = 'mongodb://localhost:27017'\n",
    "\n",
    "# client = pymongo.MongoClient(conn)\n",
    "\n",
    "# db = client.mars_db\n",
    "\n",
    "# mars_info_dictionary = scrape()\n",
    "\n",
    "#db.mars_info.update_one({}, {\"$set\": mars_info_dictionary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('622d0f0de211cf2e33c60d5c'),\n",
       " 'featured_image': 'https://spaceimages-mars.com/image/featured/mars1.jpg',\n",
       " 'hemisphere_images': {'Cerberus Hemisphere Enhanced': 'https://marshemispheres.com/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg',\n",
       "  'Schiaparelli Hemisphere Enhanced': 'https://marshemispheres.com/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg',\n",
       "  'Syrtis Major Hemisphere Enhanced': 'https://marshemispheres.com/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg',\n",
       "  'Valles Marineris Hemisphere Enhanced': 'https://marshemispheres.com/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg'},\n",
       " 'mars_facts': [{'name': 'Equatorial Diameter:', 'measure': '6,792 km'},\n",
       "  {'name': 'Polar Diameter:', 'measure': '6,752 km'},\n",
       "  {'name': 'Mass:', 'measure': '6.39 × 10^23 kg (0.11 Earths)'},\n",
       "  {'name': 'Moons:', 'measure': '2 ( Phobos & Deimos )'},\n",
       "  {'name': 'Orbit Distance:', 'measure': '227,943,824 km (1.38 AU)'},\n",
       "  {'name': 'Orbit Period:', 'measure': '687 days (1.9 years)'},\n",
       "  {'name': 'Surface Temperature:', 'measure': '-87 to -5 °C'},\n",
       "  {'name': 'First Record:', 'measure': '2nd millennium BC'},\n",
       "  {'name': 'Recorded By:', 'measure': 'Egyptian astronomers'}],\n",
       " 'news_paragraph': 'To go along with the stunning 1.8-billion-pixel image, a new video offers a sweeping view of the Red Planet.',\n",
       " 'news_titles': \"NASA's Curiosity Mars Rover Snaps Its Highest-Resolution Panorama Yet\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "db = client.mars_db\n",
    "\n",
    "data = list(db.mars_info.find())[0]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pymongo\n",
    "from flask import Flask, render_template\n",
    "from scrape_mars import scrape\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    conn = 'mongodb://localhost:27017'\n",
    "\n",
    "    client = pymongo.MongoClient(conn)\n",
    "\n",
    "    db = client.mars_db\n",
    "    \n",
    "    mars = list(db.mars_info.find())[0]\n",
    "    \n",
    "    return render_template('index.html', mars=mars)\n",
    "\n",
    "\n",
    "@app.route('/scrape')\n",
    "def scrape():\n",
    "    conn = 'mongodb://localhost:27017'\n",
    "\n",
    "    client = pymongo.MongoClient(conn)\n",
    "\n",
    "    db = client.mars_db\n",
    "    \n",
    "    mars_info_dictionary = scrape()\n",
    "    \n",
    "    db.mars_info.update_one({}, {\"$set\": mars_info_dictionary}, upsert=True)\n",
    "    \n",
    "    return redirect('/', code=302)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PythonData] *",
   "language": "python",
   "name": "conda-env-.conda-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
